# -*- coding: utf-8 -*-
"""giafinalCVDNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14rGv9vA_z4r63ERM_P-60wCA6FMKKowQ
"""

# Gia Renemae Calip
# CS 622 - 1002
# Dr. Junggab Son
# Team AlgoThinkers
# Neural Network Program

# Scikeras install was needed for the implementation of the newer version of KerasClassifier

pip install scikeras

# Importing libraries needed for neural network building
# Pandas for cleaning and preparing the data
import pandas as pd
# Numpy for arrray processing
import numpy as np
# Sklearn for sourcing analysis libraries to process things such as preprocessing and classification
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from sklearn.preprocessing import LabelBinarizer
# Tensorflow for the deploymernt of machine learning applications
import tensorflow as tf
from tensorflow.python.keras import Sequential
from tensorflow.python.keras.layers import Dense, Dropout
from tensorflow.python.keras.utils.np_utils import to_categorical
# Matplotlib for visualization of tables/graphs
import matplotlib.pyplot as plt
# Seaborn to help with tables and graphs
import seaborn as sns
# Imported csv and re for accessing the data file
import csv
import re

with open ('/content/cardio_train.csv', "r") as file:
    cardio_data = pd.read_csv('/content/cardio_train.csv', sep=',')
    cardio_data.columns = ((cardio_data.columns.str).replace("^ ","")).str.replace(" $","")

# Defining the risk classifications by evalutating the row and sorting to four different categories
def classify_risk(row):
    cardiovasc = row['cardio']
    cholesterol = row['cholesterol']
    glucose = row['gluc']
    ap_hi = row['ap_hi']
    ap_lo = row['ap_lo']
    alcohol = row['alco']
    smoke = row['smoke']


    # No Risk
    if (cardiovasc == 0 and cholesterol == 1 and glucose == 1 and
        ap_hi <= 120 and ap_lo <= 80 and alcohol == 0 and smoke == 0):
        return "No Risk"
    # Low Risk
    elif (cardiovasc == 0 and cholesterol <= 2 and glucose <= 2 and
          ap_hi <= 130 and ap_lo <= 85 and alcohol <= 1 and smoke <= 1):
        return "Low Risk"
    # Moderate Risk
    elif (cardiovasc <= 1 and cholesterol <= 3 and glucose <= 3 and
          130 <= ap_hi <= 150 and 85 <= ap_lo <= 90 and alcohol <= 1 and smoke <= 1):
        return "Moderate Risk"
    # High Risk
    elif (cardiovasc <= 1 and cholesterol <= 3 and glucose <= 3 and
          ap_hi <= 200 and ap_lo <= 120 and alcohol <= 1 and smoke <= 1):
        return "High Risk"
    return "Uncategorized"

# Applying the classifications to each row, creates new frame, and excludes rows that does not fit the categories
cardio_data['risk_category'] = cardio_data.apply(classify_risk, axis=1)
risk_data = cardio_data[cardio_data['risk_category'] != 'Uncategorized']

# Removes unnecessary columns
x = risk_data.drop(columns=['cardio', 'risk_category'])
y = risk_data['risk_category']

# Labels and transforms
encoded_label = LabelEncoder()
y_encoded = encoded_label.fit_transform(y)

# Used to turn categorical data to binary
y_categorical = to_categorical(y_encoded)

print(f"Encoded classes: {encoded_label.classes_}")

# Standardizes the features
scaler = StandardScaler()
scaled_x = scaler.fit_transform(x)
print("Data preprocessing completed successfully.")

# Used to updgrade tensorflow to the latest version

!pip install --upgrade tensorflow

# Reiteration of needed librariese AFTER tensorflow upgrade
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import StratifiedKFold

# Creates a feedforward neural network that includes optimizer and neurons, stacking layers,
# and compiles model for classification
def create_model(input_dim, output_dim):
    model = Sequential([
        Dense(64, input_dim=input_dim, activation='relu'),
        Dense(32, activation='relu'),
        Dense(output_dim, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Parameters of K-fold which evaluates the model
k_values = [5]
optimal_k = None
best_f1_score = 0.0
metrics_results = []

# Setting the K-Fold Cross-Validation, where k is equal to 5
k = 5
stratkf = StratifiedKFold(n_splits=k, shuffle=True, random_state=1)
scores = []
fold = 1
for train_index, test_index in stratkf.split(scaled_x, y_encoded):
    train_x, test_x = scaled_x[train_index], scaled_x[test_index]
    train_y, test_y = y_encoded[train_index], y_encoded[test_index]

    # Encoding labels to categorical
    y_train_categorical = to_categorical(train_y)
    y_test_categorical = to_categorical(test_y)

   # Creating and training the model
    model = create_model(train_x.shape[1], y_train_categorical.shape[1])
    model.fit(train_x, y_train_categorical, epochs=20, batch_size=32, validation_data=(test_x, y_test_categorical), verbose=0)

    # Evaluating the model
    score = model.evaluate(test_x, y_test_categorical, verbose=0)
    scores.append(score[1])
    print(f"Fold {fold} - Accuracy: {score[1]:.2f}")
    fold += 1

print(f"\nAverage Accuracy: {np.mean(scores):.2f}")

# Reiteration of needed librariese AFTER tensorflow upgrade
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import numpy as np

# Generating predictions with the trained model
y_pred = model.predict(test_x)
y_pred_class = np.argmax(y_pred, axis=1)
y_true_class = np.argmax(y_test_categorical, axis=1)

# Defining className
className = encoded_label.classes_

# Confusion matrix set up and visualization
cm = confusion_matrix(y_true_class, y_pred_class)
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=className, yticklabels=className)
plt.title("Confusion Matrix")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# Probability predictions for ROC and AUC
y_pred_prob = model.predict(test_x)

# Plots ROC curves per class
fpr, tpr, roc_auc = {}, {}, {}
for i in range(y_pred_prob.shape[1]):
    fpr[i], tpr[i], _ = roc_curve(y_test_categorical[:, i], y_pred_prob[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plots ROC curves for all classes
plt.figure(figsize=(10, 7))
for i in range(y_pred_prob.shape[1]):
    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')

# Plotting of the bazeline
plt.plot([0, 1], [0, 1], 'k--')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.show()

# Displays detailed results for k-values
print("\nDetailed Results for all k:")
for result in metrics_results:
    print(f"k={result['k']} -> Accuracy: {result['accuracy']:.4f}, Precision: {result['precision']:.4f}, Recall: {result['recall']:.4f}, F1 Score: {result['f1_score']:.4f}")

# Confusion matrix in text
cm = confusion_matrix(y_true_class, y_pred_class)
print("Confusion Matrix (Text Output):")
print(cm)

# Reformats results for easier reading
cm_df = pd.DataFrame(cm, index=encoded_label.classes_, columns=encoded_label.classes_)
print("\nFormatted Confusion Matrix (with labels):")
print(cm_df)

# Final classification results
report = classification_report(y_true_class, y_pred_class, target_names=encoded_label.classes_)
print("Classification Report:\n", report)